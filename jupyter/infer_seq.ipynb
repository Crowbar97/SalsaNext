{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import imp\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# import torch.nn as nn\n",
    "from torch import nn\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# laserscan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaserScan:\n",
    "    \"\"\"Class that contains LaserScan with x,y,z,r\"\"\"\n",
    "    EXTENSIONS_SCAN = ['.bin']\n",
    "\n",
    "    def __init__(self,\n",
    "                 project=False,\n",
    "                 H=64,\n",
    "                 W=1024,\n",
    "                 fov_up=3.0,\n",
    "                 fov_down=-25.0):\n",
    "        self.project = project\n",
    "        self.proj_H = H\n",
    "        self.proj_W = W\n",
    "        self.proj_fov_up = fov_up\n",
    "        self.proj_fov_down = fov_down\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\" Reset scan members. \"\"\"\n",
    "        self.points = np.zeros((0, 3), dtype=np.float32)  # [m, 3]: x, y, z\n",
    "        self.remissions = np.zeros((0, 1), dtype=np.float32)  # [m ,1]: remission\n",
    "\n",
    "        # projected range image - [H,W] range (-1 is no data)\n",
    "        self.proj_range = np.full((self.proj_H, self.proj_W), -1,\n",
    "                                  dtype=np.float32)\n",
    "\n",
    "        # unprojected range (list of depths for each point)\n",
    "        self.unproj_range = np.zeros((0, 1), dtype=np.float32)\n",
    "\n",
    "        # projected point cloud xyz - [H,W,3] xyz coord (-1 is no data)\n",
    "        self.proj_xyz = np.full((self.proj_H, self.proj_W, 3), -1,\n",
    "                                dtype=np.float32)\n",
    "\n",
    "        # projected remission - [H,W] intensity (-1 is no data)\n",
    "        self.proj_remission = np.full((self.proj_H, self.proj_W), -1,\n",
    "                                      dtype=np.float32)\n",
    "\n",
    "        # projected index (for each pixel, what I am in the pointcloud)\n",
    "        # [H,W] index (-1 is no data)\n",
    "        self.proj_idx = np.full((self.proj_H, self.proj_W), -1,\n",
    "                                dtype=np.int32)\n",
    "\n",
    "        # for each point, where it is in the range image\n",
    "        self.proj_x = np.zeros((0, 1), dtype=np.int32)  # [m, 1]: x\n",
    "        self.proj_y = np.zeros((0, 1), dtype=np.int32)  # [m, 1]: y\n",
    "\n",
    "        # mask containing for each pixel, if it contains a point or not\n",
    "        self.proj_mask = np.zeros((self.proj_H, self.proj_W),\n",
    "                                  dtype=np.int32)  # [H,W] mask\n",
    "\n",
    "    def size(self):\n",
    "        \"\"\" Return the size of the point cloud. \"\"\"\n",
    "        return self.points.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size()\n",
    "\n",
    "    def open_scan(self, filename):\n",
    "        \"\"\" Open raw scan and fill in attributes\n",
    "        \"\"\"\n",
    "        # reset just in case there was an open structure\n",
    "        self.reset()\n",
    "\n",
    "        # check filename is string\n",
    "        if not isinstance(filename, str):\n",
    "            raise TypeError(\"Filename should be string type, \"\n",
    "                            \"but was {type}\".format(type=str(type(filename))))\n",
    "\n",
    "        # check extension is a laserscan\n",
    "        if not any(filename.endswith(ext) for ext in self.EXTENSIONS_SCAN):\n",
    "            raise RuntimeError(\"Filename extension is not valid scan file.\")\n",
    "\n",
    "        # if all goes well, open pointcloud\n",
    "        scan = np.fromfile(filename, dtype=np.float32)\n",
    "        scan = scan.reshape((-1, 4))\n",
    "\n",
    "        # put in attribute\n",
    "        points = scan[:, 0:3]  # get xyz\n",
    "        remissions = scan[:, 3]  # get remission\n",
    "        \n",
    "        self.set_points(points, remissions)\n",
    "\n",
    "    def set_points(self, points, remissions=None):\n",
    "        \"\"\" Set scan attributes (instead of opening from file)\n",
    "        \"\"\"\n",
    "        # reset just in case there was an open structure\n",
    "        self.reset()\n",
    "\n",
    "        # check scan makes sense\n",
    "        if not isinstance(points, np.ndarray):\n",
    "            raise TypeError(\"Scan should be numpy array\")\n",
    "\n",
    "        # check remission makes sense\n",
    "        if remissions is not None and not isinstance(remissions, np.ndarray):\n",
    "            raise TypeError(\"Remissions should be numpy array\")\n",
    "\n",
    "        # put in attribute\n",
    "        self.points = points  # get xyz\n",
    "        if remissions is not None:\n",
    "            self.remissions = remissions  # get remission\n",
    "        else:\n",
    "            self.remissions = np.zeros((points.shape[0]), dtype=np.float32)\n",
    "\n",
    "        # if projection is wanted, then do it and fill in the structure\n",
    "        if self.project:\n",
    "            self.do_range_projection()\n",
    "\n",
    "    def do_range_projection(self):\n",
    "        \"\"\" Project a pointcloud into a spherical projection image.projection.\n",
    "            Function takes no arguments because it can be also called externally\n",
    "            if the value of the constructor was not set (in case you change your\n",
    "            mind about wanting the projection)\n",
    "        \"\"\"\n",
    "        # laser parameters\n",
    "        fov_up = self.proj_fov_up / 180.0 * np.pi  # field of view up in rad\n",
    "        fov_down = self.proj_fov_down / 180.0 * np.pi  # field of view down in rad\n",
    "        fov = abs(fov_down) + abs(fov_up)  # get field of view total in rad\n",
    "\n",
    "        # get depth of all points\n",
    "        depth = np.linalg.norm(self.points, 2, axis=1)\n",
    "\n",
    "        # get scan components\n",
    "        scan_x = self.points[:, 0]\n",
    "        scan_y = self.points[:, 1]\n",
    "        scan_z = self.points[:, 2]\n",
    "\n",
    "        # get angles of all points\n",
    "        yaw = -np.arctan2(scan_y, scan_x)\n",
    "        pitch = np.arcsin(scan_z / depth)\n",
    "\n",
    "        # get projections in image coords\n",
    "        proj_x = 0.5 * (yaw / np.pi + 1.0)  # in [0.0, 1.0]\n",
    "        proj_y = 1.0 - (pitch + abs(fov_down)) / fov  # in [0.0, 1.0]\n",
    "\n",
    "        # scale to image size using angular resolution\n",
    "        proj_x *= self.proj_W  # in [0.0, W]\n",
    "        proj_y *= self.proj_H  # in [0.0, H]\n",
    "\n",
    "        # round and clamp for use as index\n",
    "        proj_x = np.floor(proj_x)\n",
    "        proj_x = np.minimum(self.proj_W - 1, proj_x)\n",
    "        proj_x = np.maximum(0, proj_x).astype(np.int32)  # in [0,W-1]\n",
    "        self.proj_x = np.copy(proj_x)  # store a copy in orig order\n",
    "\n",
    "        proj_y = np.floor(proj_y)\n",
    "        proj_y = np.minimum(self.proj_H - 1, proj_y)\n",
    "        proj_y = np.maximum(0, proj_y).astype(np.int32)  # in [0,H-1]\n",
    "        self.proj_y = np.copy(proj_y)  # stope a copy in original order\n",
    "\n",
    "        # copy of depth in original order\n",
    "        self.unproj_range = np.copy(depth)\n",
    "\n",
    "        # order in decreasing depth\n",
    "        indices = np.arange(depth.shape[0])\n",
    "        order = np.argsort(depth)[::-1]\n",
    "        depth = depth[order]\n",
    "        indices = indices[order]\n",
    "        points = self.points[order]\n",
    "        remission = self.remissions[order]\n",
    "        proj_y = proj_y[order]\n",
    "        proj_x = proj_x[order]\n",
    "\n",
    "        # assing to images\n",
    "        self.proj_range[proj_y, proj_x] = depth\n",
    "        self.proj_xyz[proj_y, proj_x] = points\n",
    "        self.proj_remission[proj_y, proj_x] = remission\n",
    "        self.proj_idx[proj_y, proj_x] = indices\n",
    "        self.proj_mask = (self.proj_idx > 0).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parser.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTENSIONS_SCAN = ['.bin']\n",
    "EXTENSIONS_LABEL = ['.label']\n",
    "\n",
    "\n",
    "def is_scan(filename):\n",
    "    return any(filename.endswith(ext) for ext in EXTENSIONS_SCAN)\n",
    "\n",
    "\n",
    "def is_label(filename):\n",
    "    return any(filename.endswith(ext) for ext in EXTENSIONS_LABEL)\n",
    "\n",
    "\n",
    "class SemanticKitti(Dataset):\n",
    "    def __init__(self,\n",
    "                 # directory where data is\n",
    "                 dataset_dir_path,\n",
    "                 # label dict: (e.g 10: \"car\")\n",
    "                 labels,\n",
    "                 # colors dict bgr (e.g 10: [255, 0, 0])\n",
    "                 color_map,\n",
    "                 # classes to learn (0 to N-1 for xentropy)\n",
    "                 learning_map,\n",
    "                 # inverse of previous (recover labels)\n",
    "                 learning_map_inv,\n",
    "                 # sensor to parse scans from\n",
    "                 sensor,\n",
    "                 # max number of points present in dataset\n",
    "                 max_points=150000,\n",
    "                ):\n",
    "        # save deats\n",
    "        self.dataset_dir_path = dataset_dir_path\n",
    "        \n",
    "        self.labels = labels\n",
    "        self.color_map = color_map\n",
    "        self.learning_map = learning_map\n",
    "        self.learning_map_inv = learning_map_inv\n",
    "        \n",
    "        self.sensor = sensor\n",
    "        self.sensor_img_H = sensor[\"img_prop\"][\"height\"]\n",
    "        self.sensor_img_W = sensor[\"img_prop\"][\"width\"]\n",
    "        self.sensor_img_means = torch.tensor(sensor[\"img_means\"], dtype=torch.float)\n",
    "        self.sensor_img_stds = torch.tensor(sensor[\"img_stds\"], dtype=torch.float)\n",
    "        self.sensor_fov_up = sensor[\"fov_up\"]\n",
    "        self.sensor_fov_down = sensor[\"fov_down\"]\n",
    "        print('SENSOR:')\n",
    "        pprint(self.sensor)\n",
    "        \n",
    "        self.max_points = max_points\n",
    "    \n",
    "        # get number of classes (can't be len(self.learning_map) because there\n",
    "        # are multiple repeated entries, so the number that matters is how many\n",
    "        # there are for the xentropy)\n",
    "        self.nclasses = len(self.learning_map_inv)\n",
    "    \n",
    "        # sanity checks\n",
    "    \n",
    "        # make sure directory exists\n",
    "        if os.path.isdir(self.dataset_dir_path):\n",
    "            print(\"Dataset folder exists! Using clouds from %s\" % self.dataset_dir_path)\n",
    "        else:\n",
    "            raise ValueError(\"Dataset folder doesn't exist! Exiting...\")\n",
    "    \n",
    "        # make sure labels is a dict\n",
    "        assert(isinstance(self.labels, dict))\n",
    "    \n",
    "        # make sure color_map is a dict\n",
    "        assert(isinstance(self.color_map, dict))\n",
    "    \n",
    "        # make sure learning_map is a dict\n",
    "        assert(isinstance(self.learning_map, dict))\n",
    "    \n",
    "        # placeholder for filenames\n",
    "        self.scan_files = []\n",
    "        self.label_files = []\n",
    "    \n",
    "        # parsing dataset\n",
    "        print(\"Parsing dataset... \")\n",
    "\n",
    "        # get paths for each\n",
    "        scan_path = self.dataset_dir_path\n",
    "\n",
    "        # get files\n",
    "        scan_files = [ os.path.join(dp, f)\n",
    "                      for dp, dn, fn in os.walk(os.path.expanduser(scan_path))\n",
    "                      for f in fn if is_scan(f) ]\n",
    "\n",
    "        # extend list\n",
    "        self.scan_files.extend(scan_files)\n",
    "    \n",
    "        # sort for correspondance\n",
    "        self.scan_files.sort()\n",
    "    \n",
    "        print(\"Using {} scans\".format(len(self.scan_files)))\n",
    "  \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # get item in tensor shape\n",
    "        scan_file = self.scan_files[index]\n",
    "    \n",
    "        # open a semantic laserscan\n",
    "        scan = LaserScan(project=True,\n",
    "                         H=self.sensor_img_H,\n",
    "                         W=self.sensor_img_W,\n",
    "                         fov_up=self.sensor_fov_up,\n",
    "                         fov_down=self.sensor_fov_down)\n",
    "    \n",
    "        # open and obtain scan\n",
    "        scan.open_scan(scan_file)\n",
    "        \n",
    "        # make a tensor of the uncompressed data (with the max num points)\n",
    "        unproj_n_points = scan.points.shape[0]\n",
    "        unproj_xyz = torch.full((self.max_points, 3), -1.0, dtype=torch.float)\n",
    "        unproj_xyz[:unproj_n_points] = torch.from_numpy(scan.points)\n",
    "        unproj_range = torch.full([self.max_points], -1.0, dtype=torch.float)\n",
    "        unproj_range[:unproj_n_points] = torch.from_numpy(scan.unproj_range)\n",
    "        unproj_remissions = torch.full([self.max_points], -1.0, dtype=torch.float)\n",
    "        unproj_remissions[:unproj_n_points] = torch.from_numpy(scan.remissions)\n",
    "        unproj_labels = []\n",
    "    \n",
    "        # get points and labels\n",
    "        proj_range = torch.from_numpy(scan.proj_range).clone()\n",
    "        proj_xyz = torch.from_numpy(scan.proj_xyz).clone()\n",
    "        proj_remission = torch.from_numpy(scan.proj_remission).clone()\n",
    "        proj_mask = torch.from_numpy(scan.proj_mask)\n",
    "        proj_labels = []\n",
    "        proj_x = torch.full([self.max_points], -1, dtype=torch.long)\n",
    "        proj_x[:unproj_n_points] = torch.from_numpy(scan.proj_x)\n",
    "        proj_y = torch.full([self.max_points], -1, dtype=torch.long)\n",
    "        proj_y[:unproj_n_points] = torch.from_numpy(scan.proj_y)\n",
    "        \n",
    "        # WITH remission\n",
    "        proj = torch.cat([proj_range.unsqueeze(0).clone(),\n",
    "                          proj_xyz.clone().permute(2, 0, 1),\n",
    "                          proj_remission.unsqueeze(0).clone()])\n",
    "        \n",
    "#         print('MEANS: %s' % self.sensor_img_means[:, None, None])\n",
    "#         print('STDS: %s' % self.sensor_img_stds[:, None, None])\n",
    "        proj = (proj - self.sensor_img_means[:, None, None]) / self.sensor_img_stds[:, None, None]\n",
    "        proj = proj * proj_mask.float()\n",
    "    \n",
    "        # WITHOUT remission-------------------------------------\n",
    "#         proj = torch.cat([\n",
    "#             proj_range.unsqueeze(0).clone(),\n",
    "#             proj_xyz.clone().permute(2, 0, 1),\n",
    "#         ])\n",
    "#         proj = (proj - self.sensor_img_means[:4, None, None]) / self.sensor_img_stds[:4, None, None]\n",
    "#         proj = proj * proj_mask.float()\n",
    "        # ------------------------------------------------------\n",
    "    \n",
    "        # get name and sequence\n",
    "        path_norm = os.path.normpath(scan_file)\n",
    "        path_split = path_norm.split(os.sep)\n",
    "        path_name = path_split[-1].replace(\".bin\", \".label\")\n",
    "        # print(\"path_norm: \", path_norm)\n",
    "        # print(\"path_seq\", path_seq)\n",
    "        # print(\"path_name\", path_name)\n",
    "    \n",
    "        # return\n",
    "        return ( proj,\n",
    "                 proj_mask,\n",
    "                 proj_labels,\n",
    "                 unproj_labels,\n",
    "                 path_name,\n",
    "                 proj_x,\n",
    "                 proj_y,\n",
    "                 proj_range,\n",
    "                 unproj_range,\n",
    "                 proj_xyz,\n",
    "                 unproj_xyz,\n",
    "                 proj_remission,\n",
    "                 unproj_remissions,\n",
    "                 unproj_n_points )\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.scan_files)\n",
    "  \n",
    "    @staticmethod\n",
    "    def map(label, mapdict):\n",
    "        # put label from original values to xentropy\n",
    "        # or vice-versa, depending on dictionary values\n",
    "        # make learning map a lookup table\n",
    "        maxkey = 0\n",
    "        for key, data in mapdict.items():\n",
    "            if isinstance(data, list):\n",
    "                nel = len(data)\n",
    "            else:\n",
    "                nel = 1\n",
    "            if key > maxkey:\n",
    "                maxkey = key\n",
    "        # +100 hack making lut bigger just in case there are unknown labels\n",
    "        if nel > 1:\n",
    "            lut = np.zeros((maxkey + 100, nel), dtype=np.int32)\n",
    "        else:\n",
    "            lut = np.zeros((maxkey + 100), dtype=np.int32)\n",
    "        for key, data in mapdict.items():\n",
    "            try:\n",
    "                lut[key] = data\n",
    "            except IndexError:\n",
    "                print(\"Wrong key \", key)\n",
    "        # do the mapping\n",
    "        return lut[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# parser.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Parser():\n",
    "    # standard conv, BN, relu\n",
    "    def __init__(self,\n",
    "                 dataset_dir_path,\n",
    "                 \n",
    "                 # labels in data\n",
    "                 labels,\n",
    "                 # color for each label\n",
    "                 color_map,\n",
    "                 # mapping for training labels\n",
    "                 learning_map,\n",
    "                 # recover labels from xentropy\n",
    "                 learning_map_inv,\n",
    "                 \n",
    "                 # sensor to use\n",
    "                 sensor,\n",
    "                 # max points in each scan in entire dataset\n",
    "                 max_points,\n",
    "                 \n",
    "                 # batch size for train and val\n",
    "                 batch_size,\n",
    "                 # threads to load data\n",
    "                 workers,\n",
    "                 # shuffle training set?\n",
    "                 shuffle_train=True\n",
    "                ):\n",
    "        super(Parser, self).__init__()\n",
    "  \n",
    "        # parameters\n",
    "        self.dataset_dir_path = dataset_dir_path\n",
    "        \n",
    "        self.labels = labels\n",
    "        self.color_map = color_map\n",
    "        self.learning_map = learning_map\n",
    "        self.learning_map_inv = learning_map_inv\n",
    "        \n",
    "        self.sensor = sensor\n",
    "        self.max_points = max_points\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.workers = workers\n",
    "        self.shuffle_train = shuffle_train\n",
    "    \n",
    "        # number of classes that matters is the one for xentropy\n",
    "        self.nclasses = len(self.learning_map_inv)\n",
    "    \n",
    "        # Load test dataset\n",
    "        self.test_dataset = SemanticKitti(self.dataset_dir_path,\n",
    "                                          self.labels,\n",
    "                                          self.color_map,\n",
    "                                          self.learning_map,\n",
    "                                          self.learning_map_inv,\n",
    "                                          self.sensor,\n",
    "                                          self.max_points)\n",
    "    \n",
    "        self.testloader = torch.utils.data.DataLoader(self.test_dataset,\n",
    "                                                       batch_size=self.batch_size,\n",
    "                                                       shuffle=False,\n",
    "                                                       num_workers=self.workers,\n",
    "                                                       drop_last=True)\n",
    "        \n",
    "        assert len(self.testloader) > 0\n",
    "        self.testiter = iter(self.testloader)\n",
    "    \n",
    "  \n",
    "    def get_test_batch(self):\n",
    "        scans = self.testiter.next()\n",
    "        return scans\n",
    "  \n",
    "    def get_test_set(self):\n",
    "        return self.testloader\n",
    "  \n",
    "    def get_test_size(self):\n",
    "        return len(self.testloader)\n",
    "  \n",
    "    def get_n_classes(self):\n",
    "        return self.nclasses\n",
    "  \n",
    "    def get_original_class_string(self, idx):\n",
    "        return self.labels[idx]\n",
    "  \n",
    "    def get_xentropy_class_string(self, idx):\n",
    "        return self.labels[self.learning_map_inv[idx]]\n",
    "  \n",
    "    def to_original(self, label):\n",
    "        # put label in original values\n",
    "        return SemanticKitti.map(label, self.learning_map_inv)\n",
    "  \n",
    "    def to_xentropy(self, label):\n",
    "        # put label in xentropy values\n",
    "        return SemanticKitti.map(label, self.learning_map)\n",
    "  \n",
    "    def to_color(self, label):\n",
    "        # put label in original values\n",
    "        label = SemanticKitti.map(label, self.learning_map_inv)\n",
    "        # put label in color\n",
    "        return SemanticKitti.map(label, self.color_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# segmentator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Add, self).__init__()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return x + y\n",
    "\n",
    "\n",
    "class resBlock_with_add(nn.Module):\n",
    "    def __init__(self, conv, act, bn):\n",
    "        super(resBlock_with_add, self).__init__()\n",
    "\n",
    "        self.conv = conv\n",
    "        self.act = act\n",
    "        self.bn = bn\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        res = self.conv(x)\n",
    "        res = self.act(res)\n",
    "        res = self.bn(res)\n",
    "        return res + y\n",
    "\n",
    "\n",
    "class Trans(nn.Module):\n",
    "    def __init__(self, trans, trans_act, trans_bn):\n",
    "        super(Trans, self).__init__()\n",
    "        self.trans = trans\n",
    "        self.trans_act = trans_act\n",
    "        self.trans_bn = trans_bn\n",
    "\n",
    "    def forward(self, x):\n",
    "        upA = self.trans(x)\n",
    "        upA = self.trans_act(upA)\n",
    "        upA = self.trans_bn(upA)\n",
    "        return upA\n",
    "\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, f_g, f_l, f_int):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.Wg = nn.Sequential(nn.Conv2d(f_g, f_int, kernel_size=1, padding=0, stride=1),\n",
    "                                nn.BatchNorm2d(f_int))\n",
    "\n",
    "        self.Wx = nn.Sequential(nn.Conv2d(f_l, f_int, kernel_size=1, padding=0, stride=1),\n",
    "                                nn.BatchNorm2d(f_int))\n",
    "\n",
    "        self.psi = nn.Sequential(nn.Conv2d(f_int, 1, kernel_size=1, padding=0, stride=1),\n",
    "                                 nn.BatchNorm2d(1),\n",
    "                                 nn.Sigmoid())\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        g1 = self.Wg(g)\n",
    "        x1 = self.Wx(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi\n",
    "\n",
    "\n",
    "class ResContextBlock(nn.Module):\n",
    "    def __init__(self, in_filters, out_filters, kernel_size=(3, 3), stride=1):\n",
    "        super(ResContextBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_filters, out_filters, kernel_size=(1, 1), stride=stride)\n",
    "        self.act1 = nn.LeakyReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_filters, out_filters, kernel_size, padding=1)\n",
    "        self.act2 = nn.LeakyReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(out_filters)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(out_filters, out_filters, kernel_size, padding=1)\n",
    "        self.act3 = nn.LeakyReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(out_filters)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.conv1(x)\n",
    "        shortcut = self.act1(shortcut)\n",
    "\n",
    "        resA = self.conv2(x)\n",
    "        resA = self.act2(resA)\n",
    "        resA = self.bn1(resA)\n",
    "\n",
    "        resA = self.conv3(resA)\n",
    "        resA = self.act3(resA)\n",
    "        resA = self.bn2(resA)\n",
    "        return resA + shortcut\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_filters, out_filters, dropout_rate, kernel_size=(3, 3), stride=1,\n",
    "                 pooling=True, drop_out=True):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.pooling = pooling\n",
    "        self.drop_out = drop_out\n",
    "        self.conv1 = nn.Conv2d(in_filters, out_filters, kernel_size=(1, 1), stride=stride)\n",
    "        self.act1 = nn.LeakyReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_filters, out_filters, kernel_size=kernel_size, padding=1)\n",
    "        self.act2 = nn.LeakyReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(out_filters)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(out_filters, out_filters, kernel_size=kernel_size, padding=1)\n",
    "        self.act3 = nn.LeakyReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(out_filters)\n",
    "\n",
    "        if pooling:\n",
    "            self.dropout = nn.Dropout2d(p=dropout_rate)\n",
    "            self.pool = nn.AvgPool2d(kernel_size=kernel_size, stride=2, padding=1)\n",
    "        else:\n",
    "            self.dropout = nn.Dropout2d(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.conv1(x)\n",
    "        shortcut = self.act1(shortcut)\n",
    "\n",
    "        resA = self.conv2(x)\n",
    "        resA = self.act2(resA)\n",
    "        resA = self.bn1(resA)\n",
    "\n",
    "        resA = self.conv3(resA)\n",
    "        resA = self.act3(resA)\n",
    "        resA = self.bn2(resA)\n",
    "        resA = shortcut + resA\n",
    "\n",
    "        if self.pooling:\n",
    "            if self.drop_out:\n",
    "                resB = self.dropout(resA)\n",
    "            else:\n",
    "                resB = resA\n",
    "            resB = self.pool(resB)\n",
    "\n",
    "            return resB, resA\n",
    "        else:\n",
    "            if self.drop_out:\n",
    "                resB = self.dropout(resA)\n",
    "            else:\n",
    "                resB = resA\n",
    "            return resB\n",
    "\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_filters, out_filters, dropout_rate, kernel_size=(3, 3),drop_out=True):\n",
    "        super(UpBlock, self).__init__()\n",
    "        self.drop_out = drop_out\n",
    "        self.trans = nn.ConvTranspose2d(in_filters, out_filters, kernel_size, stride=(2, 2), padding=1)\n",
    "        self.trans_act = nn.LeakyReLU()\n",
    "        self.trans_bn = nn.BatchNorm2d(out_filters)\n",
    "\n",
    "        self.dropout1 = nn.Dropout2d(p=dropout_rate)\n",
    "        self.dropout2 = nn.Dropout2d(p=dropout_rate)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(out_filters, out_filters, kernel_size, padding=1)\n",
    "        self.act1 = nn.LeakyReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(out_filters)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_filters, out_filters, kernel_size, padding=1)\n",
    "        self.act2 = nn.LeakyReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(out_filters)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(out_filters, out_filters, kernel_size, padding=1)\n",
    "        self.act3 = nn.LeakyReLU()\n",
    "        self.bn3 = nn.BatchNorm2d(out_filters)\n",
    "        self.dropout3 = nn.Dropout2d(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        upA = self.trans(x)\n",
    "\n",
    "        if upA.shape != skip.shape:\n",
    "            upA = F.pad(upA, (0, 1, 0, 1), mode='replicate')\n",
    "\n",
    "        upA = self.trans_act(upA)\n",
    "        upA = self.trans_bn(upA)\n",
    "        if self.drop_out:\n",
    "            upA = self.dropout1(upA)\n",
    "        upB = upA + skip\n",
    "        if self.drop_out:\n",
    "            upB = self.dropout2(upB)\n",
    "\n",
    "        upE = self.conv1(upB)\n",
    "        upE = self.act1(upE)\n",
    "        upE = self.bn1(upE)\n",
    "\n",
    "        upE = self.conv2(upE)\n",
    "        upE = self.act2(upE)\n",
    "        upE = self.bn2(upE)\n",
    "\n",
    "        upE = self.conv3(upE)\n",
    "        upE = self.act3(upE)\n",
    "        upE = self.bn3(upE)\n",
    "        if self.drop_out:\n",
    "            upE = self.dropout3(upE)\n",
    "\n",
    "        return upE\n",
    "\n",
    "\n",
    "class SalsaNet(nn.Module):\n",
    "    def __init__(self, ARCH, nclasses, path=None, path_append=\"\", strict=False):\n",
    "        super(SalsaNet, self).__init__()\n",
    "        self.ARCH = ARCH\n",
    "        self.nclasses = nclasses\n",
    "        self.path = path\n",
    "        self.path_append = path_append\n",
    "        self.strict = False\n",
    "\n",
    "         # WITH remission\n",
    "        self.downCntx = ResContextBlock(5, 32)\n",
    "        \n",
    "        # WITHOUT remission\n",
    "#         self.downCntx = ResContextBlock(4, 32)\n",
    "\n",
    "        self.resBlock1 = ResBlock(32, 32, 0.2, pooling=True, drop_out=False)\n",
    "        self.resBlock2 = ResBlock(32, 2 * 32, 0.2, pooling=True)\n",
    "        self.resBlock3 = ResBlock(2 * 32, 4 * 32, 0.2, pooling=True)\n",
    "        self.resBlock4 = ResBlock(4 * 32, 8 * 32, 0.2, pooling=True)\n",
    "        self.resBlock5 = ResBlock(8 * 32, 16 * 32, 0.2, pooling=True)\n",
    "        self.resBlock6 = ResBlock(16 * 32, 16 * 32, 0.2, pooling=False)\n",
    "\n",
    "        self.upBlock1 = UpBlock(16 * 32, 16 * 32, 0.2)\n",
    "        self.upBlock2 = UpBlock(16 * 32, 8 * 32, 0.2)\n",
    "        self.upBlock3 = UpBlock(8 * 32, 4 * 32, 0.2)\n",
    "        self.upBlock4 = UpBlock(4 * 32, 2 * 32, 0.2)\n",
    "        self.upBlock5 = UpBlock(2 * 32, 32, 0.2, drop_out=False)\n",
    "\n",
    "        self.logits = nn.Conv2d(32, nclasses, kernel_size=(1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        downCntx = self.downCntx(x)\n",
    "        down0c, down0b = self.resBlock1(downCntx)\n",
    "        down1c, down1b = self.resBlock2(down0c)\n",
    "        down2c, down2b = self.resBlock3(down1c)\n",
    "        down3c, down3b = self.resBlock4(down2c)\n",
    "        down4c, down4b = self.resBlock5(down3c)\n",
    "        down5b = self.resBlock6(down4c)\n",
    "\n",
    "        up4e = self.upBlock1(down5b, down4b)\n",
    "        up3e = self.upBlock2(up4e, down3b)\n",
    "        up2e = self.upBlock3(up3e, down2b)\n",
    "        up1e = self.upBlock4(up2e, down1b)\n",
    "        up0e = self.upBlock5(up1e, down0b)\n",
    "\n",
    "        logits = self.logits(up0e)\n",
    "        logits = F.softmax(logits, dim=1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# KNN.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_gaussian_kernel(kernel_size=3, sigma=2, channels=1):\n",
    "    # Create a x, y coordinate grid of shape (kernel_size, kernel_size, 2)\n",
    "    x_coord = torch.arange(kernel_size)\n",
    "    x_grid = x_coord.repeat(kernel_size).view(kernel_size, kernel_size)\n",
    "    y_grid = x_grid.t()\n",
    "    xy_grid = torch.stack([x_grid, y_grid], dim=-1).float()\n",
    "\n",
    "    mean = (kernel_size - 1) / 2.\n",
    "    variance = sigma ** 2.\n",
    "\n",
    "    # Calculate the 2-dimensional gaussian kernel which is\n",
    "    # the product of two gaussian distributions for two different\n",
    "    # variables (in this case called x and y)\n",
    "    gaussian_kernel = (1. / (2. * math.pi * variance)) * \\\n",
    "                      torch.exp(-torch.sum((xy_grid - mean) ** 2., dim=-1) / (2 * variance))\n",
    "\n",
    "    # Make sure sum of values in gaussian kernel equals 1.\n",
    "    gaussian_kernel = gaussian_kernel / torch.sum(gaussian_kernel)\n",
    "\n",
    "    # Reshape to 2d depthwise convolutional weight\n",
    "    gaussian_kernel = gaussian_kernel.view(kernel_size, kernel_size)\n",
    "\n",
    "    return gaussian_kernel\n",
    "\n",
    "\n",
    "class KNN(nn.Module):\n",
    "    def __init__(self, params, nclasses):\n",
    "        super().__init__()\n",
    "        print(\"*\" * 80)\n",
    "        print(\"Cleaning point-clouds with kNN post-processing\")\n",
    "        self.knn = params[\"knn\"]\n",
    "        self.search = params[\"search\"]\n",
    "        self.sigma = params[\"sigma\"]\n",
    "        self.cutoff = params[\"cutoff\"]\n",
    "        self.nclasses = nclasses\n",
    "        print(\"kNN parameters:\")\n",
    "        print(\"knn:\", self.knn)\n",
    "        print(\"search:\", self.search)\n",
    "        print(\"sigma:\", self.sigma)\n",
    "        print(\"cutoff:\", self.cutoff)\n",
    "        print(\"nclasses:\", self.nclasses)\n",
    "        print(\"*\" * 80)\n",
    "\n",
    "    def forward(self, proj_range, unproj_range, proj_argmax, px, py):\n",
    "        ''' Warning! Only works for un-batched pointclouds.\n",
    "            If they come batched we need to iterate over the batch dimension or do\n",
    "            something REALLY smart to handle unaligned number of points in memory\n",
    "        '''\n",
    "        # get device\n",
    "        if proj_range.is_cuda:\n",
    "            device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "\n",
    "        # sizes of projection scan\n",
    "        H, W = proj_range.shape\n",
    "\n",
    "        # number of points\n",
    "        P = unproj_range.shape\n",
    "\n",
    "        # check if size of kernel is odd and complain\n",
    "        if (self.search % 2 == 0):\n",
    "            raise ValueError(\"Nearest neighbor kernel must be odd number\")\n",
    "\n",
    "        # calculate padding\n",
    "        pad = int((self.search - 1) / 2)\n",
    "\n",
    "        # unfold neighborhood to get nearest neighbors for each pixel (range image)\n",
    "        proj_unfold_k_rang = F.unfold(proj_range[None, None, ...],\n",
    "                                      kernel_size=(self.search, self.search),\n",
    "                                      padding=(pad, pad))\n",
    "\n",
    "        # index with px, py to get ALL the pcld points\n",
    "        idx_list = py * W + px\n",
    "        unproj_unfold_k_rang = proj_unfold_k_rang[:, :, idx_list]\n",
    "\n",
    "        # WARNING, THIS IS A HACK\n",
    "        # Make non valid (<0) range points extremely big so that there is no screwing\n",
    "        # up the nn self.search\n",
    "        unproj_unfold_k_rang[unproj_unfold_k_rang < 0] = float(\"inf\")\n",
    "\n",
    "        # now the matrix is unfolded TOTALLY, replace the middle points with the actual range points\n",
    "        center = int(((self.search * self.search) - 1) / 2)\n",
    "        unproj_unfold_k_rang[:, center, :] = unproj_range\n",
    "\n",
    "        # now compare range\n",
    "        k2_distances = torch.abs(unproj_unfold_k_rang - unproj_range)\n",
    "\n",
    "        # make a kernel to weigh the ranges according to distance in (x,y)\n",
    "        # I make this 1 - kernel because I want distances that are close in (x,y)\n",
    "        # to matter more\n",
    "        inv_gauss_k = (\n",
    "                1 - get_gaussian_kernel(self.search, self.sigma, 1)).view(1, -1, 1)\n",
    "        inv_gauss_k = inv_gauss_k.to(device).type(proj_range.type())\n",
    "\n",
    "        # apply weighing\n",
    "        k2_distances = k2_distances * inv_gauss_k\n",
    "\n",
    "        # find nearest neighbors\n",
    "        _, knn_idx = k2_distances.topk(\n",
    "            self.knn, dim=1, largest=False, sorted=False)\n",
    "\n",
    "        # do the same unfolding with the argmax\n",
    "        proj_unfold_1_argmax = F.unfold(proj_argmax[None, None, ...].float(),\n",
    "                                        kernel_size=(self.search, self.search),\n",
    "                                        padding=(pad, pad)).long()\n",
    "        unproj_unfold_1_argmax = proj_unfold_1_argmax[:, :, idx_list]\n",
    "\n",
    "        # get the top k predictions from the knn at each pixel\n",
    "        knn_argmax = torch.gather(\n",
    "            input=unproj_unfold_1_argmax, dim=1, index=knn_idx)\n",
    "\n",
    "        # fake an invalid argmax of classes + 1 for all cutoff items\n",
    "        if self.cutoff > 0:\n",
    "            knn_distances = torch.gather(input=k2_distances, dim=1, index=knn_idx)\n",
    "            knn_invalid_idx = knn_distances > self.cutoff\n",
    "            knn_argmax[knn_invalid_idx] = self.nclasses\n",
    "\n",
    "        # now vote\n",
    "        # argmax onehot has an extra class for objects after cutoff\n",
    "        knn_argmax_onehot = torch.zeros(\n",
    "            (1, self.nclasses + 1, P[0]), device=device).type(proj_range.type())\n",
    "        ones = torch.ones_like(knn_argmax).type(proj_range.type())\n",
    "        knn_argmax_onehot = knn_argmax_onehot.scatter_add_(1, knn_argmax, ones)\n",
    "\n",
    "        # now vote (as a sum over the onehot shit)  (don't let it choose unlabeled OR invalid)\n",
    "        knn_argmax_out = knn_argmax_onehot[:, 1:-1].argmax(dim=1) + 1\n",
    "\n",
    "        # reshape again\n",
    "        knn_argmax_out = knn_argmax_out.view(P)\n",
    "\n",
    "        return knn_argmax_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# user.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_sync_time():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    return time.perf_counter()\n",
    "\n",
    "class User():\n",
    "    def __init__(self,\n",
    "                 arch_cfg,\n",
    "                 data_cfg,\n",
    "                 dataset_dir_path,\n",
    "                 log_dir_path,\n",
    "                 model_dir_path,\n",
    "                 model_name\n",
    "                ):\n",
    "        \n",
    "        # parameters\n",
    "        self.arch_cfg = arch_cfg\n",
    "        self.data_cfg = data_cfg\n",
    "        self.dataset_dir_path = dataset_dir_path\n",
    "        self.log_dir_path = log_dir_path\n",
    "        self.model_dir_path = model_dir_path\n",
    "        self.model_name = model_name\n",
    "\n",
    "        # get the data        \n",
    "        self.parser = Parser(\n",
    "            self.dataset_dir_path,\n",
    "            \n",
    "            # ???\n",
    "            self.data_cfg['labels'],\n",
    "            # ???\n",
    "            self.data_cfg['color_map'],\n",
    "            # ???\n",
    "            self.data_cfg['learning_map'],\n",
    "            # ???\n",
    "            self.data_cfg['learning_map_inv'],\n",
    "            \n",
    "            self.arch_cfg['dataset']['sensor'],\n",
    "            self.arch_cfg['dataset']['max_points'],\n",
    "            \n",
    "            batch_size=1,\n",
    "            workers=0,\n",
    "            shuffle_train=False\n",
    "        )\n",
    "\n",
    "        # concatenate the encoder and the head\n",
    "        if self.model_name in ('salsanet', 'salsanext'):\n",
    "            with torch.no_grad():\n",
    "                print('modeldir: %s' % self.model_dir_path)\n",
    "                model_path = os.path.join(self.model_dir_path, 'SalsaNet')\n",
    "                print('model_path: %s' % model_path)\n",
    "\n",
    "                self.model = SalsaNet(self.arch_cfg,\n",
    "                                      self.parser.get_n_classes(),\n",
    "                                      model_path)\n",
    "                \n",
    "                # DONT WORK WITH TRACING\n",
    "                # SO WILL WORK ONLY WITH SINGLE GPU?\n",
    "#                 self.model = nn.DataParallel(self.model)\n",
    "                \n",
    "                torch.nn.Module.dump_patches = True\n",
    "\n",
    "                w_dict = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "#                 print(w_dict['state_dict'].keys())\n",
    "\n",
    "#                 self.model.module.load_state_dict(w_dict['state_dict'], strict=True)\n",
    "                self.model.load_state_dict(w_dict['state_dict'], strict=True)\n",
    "        else:\n",
    "            print('ERROR MODEL NAME!')\n",
    "\n",
    "        # use knn post processing?\n",
    "        self.post = None\n",
    "        if self.arch_cfg['post']['KNN']['use']:\n",
    "            self.post = KNN(self.arch_cfg['post']['KNN']['params'], self.parser.get_n_classes())\n",
    "\n",
    "        # GPU?\n",
    "        self.gpu = False\n",
    "        self.model_single = self.model\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print('Infering in device: ', self.device)\n",
    "        if torch.cuda.is_available() and torch.cuda.device_count() > 0:\n",
    "            cudnn.benchmark = True\n",
    "            cudnn.fastest = True\n",
    "            self.gpu = True\n",
    "            self.model.cuda()\n",
    "#         self.model.to(self.device)\n",
    "\n",
    "\n",
    "    def infer(self):\n",
    "        self.infer_subset(loader=self.parser.get_test_set(),\n",
    "                          to_orig_fn=self.parser.to_original)\n",
    "\n",
    "        print('Finished Infering')\n",
    "        \n",
    "\n",
    "    def infer_subset(self, loader, to_orig_fn):        \n",
    "        # switch to evaluate mode\n",
    "        self.model.eval()\n",
    "\n",
    "        # empty the cache to infer in high res\n",
    "        if self.gpu:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        with torch.no_grad():    \n",
    "            # infer time segments\n",
    "            infer_times = []\n",
    "            \n",
    "            # USING ONLY SUBSET FOR RESEARCH\n",
    "            limit = 10000\n",
    "            for i, (proj_in, proj_mask, _, _, path_name, p_x, p_y, proj_range, unproj_range, _, _, _, _, npoints) in enumerate(loader):\n",
    "                limit -= 1\n",
    "                if limit < 0:\n",
    "                    break\n",
    "                \n",
    "                # first cut to rela size (batch size one allows it)\n",
    "                p_x = p_x[0, :npoints]\n",
    "                p_y = p_y[0, :npoints]\n",
    "                proj_range = proj_range[0, :npoints]\n",
    "                unproj_range = unproj_range[0, :npoints]\n",
    "                path_name = path_name[0]\n",
    "\n",
    "                # loading data on GPU\n",
    "                if self.gpu:\n",
    "                    proj_in = proj_in.cuda()\n",
    "                    p_x = p_x.cuda()\n",
    "                    p_y = p_y.cuda()\n",
    "                    if self.post:\n",
    "                        proj_range = proj_range.cuda()\n",
    "                        unproj_range = unproj_range.cuda()\n",
    "            \n",
    "                # INFER TIME START\n",
    "                infer_time_start = get_sync_time()\n",
    "    \n",
    "                # compute output\n",
    "#                 print('PROJ IN: %s' % str(proj_in.shape))\n",
    "                proj_output = self.model(proj_in)\n",
    "#                 print('PROJ OUT: %s' % str(proj_output.shape))\n",
    "                \n",
    "                proj_argmax = proj_output[0].argmax(dim=0)\n",
    "\n",
    "                if self.post:\n",
    "                    # knn postproc\n",
    "                    unproj_argmax = self.post(proj_range, unproj_range, proj_argmax, p_x, p_y)\n",
    "                else:\n",
    "                    # put in original pointcloud using indexes\n",
    "                    unproj_argmax = proj_argmax[p_y, p_x]\n",
    "\n",
    "                # INFER TIME END\n",
    "                infer_times.append(get_sync_time() - infer_time_start)\n",
    "                print('Scan: %s' % path_name)\n",
    "                print('Infer time: %s sec' % infer_times[-1])\n",
    "                    \n",
    "                # save scan\n",
    "                # get the first scan in batch and project scan\n",
    "                pred_np = unproj_argmax.cpu().numpy()\n",
    "                pred_np = pred_np.reshape((-1)).astype(np.int32)\n",
    "\n",
    "                # map to original label\n",
    "                pred_np = to_orig_fn(pred_np)\n",
    "\n",
    "                # save scan\n",
    "                path = os.path.join(self.log_dir_path, path_name)\n",
    "                pred_np.tofile(path)\n",
    "                \n",
    "            print('*' * 30)\n",
    "            print('INFER TIME STATISTICS')\n",
    "            print('MEAN: %s' % np.mean(infer_times[1:]))\n",
    "            print('STD: %s' % np.std(infer_times[1:]))\n",
    "            print('COUNT: %s' % len(infer_times[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infer single folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## data cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_cfg = {\n",
    " 'color_map': {0: [0, 0, 0],\n",
    "               1: [0, 0, 255],\n",
    "               10: [245, 150, 100],\n",
    "               11: [245, 230, 100],\n",
    "               13: [250, 80, 100],\n",
    "               15: [150, 60, 30],\n",
    "               16: [255, 0, 0],\n",
    "               18: [180, 30, 80],\n",
    "               20: [255, 0, 0],\n",
    "               30: [30, 30, 255],\n",
    "               31: [200, 40, 255],\n",
    "               32: [90, 30, 150],\n",
    "               40: [255, 0, 255],\n",
    "               44: [255, 150, 255],\n",
    "               48: [75, 0, 75],\n",
    "               49: [75, 0, 175],\n",
    "               50: [0, 200, 255],\n",
    "               51: [50, 120, 255],\n",
    "               52: [0, 150, 255],\n",
    "               60: [170, 255, 150],\n",
    "               70: [0, 175, 0],\n",
    "               71: [0, 60, 135],\n",
    "               72: [80, 240, 150],\n",
    "               80: [150, 240, 255],\n",
    "               81: [0, 0, 255],\n",
    "               99: [255, 255, 50],\n",
    "               252: [245, 150, 100],\n",
    "               253: [200, 40, 255],\n",
    "               254: [30, 30, 255],\n",
    "               255: [90, 30, 150],\n",
    "               256: [255, 0, 0],\n",
    "               257: [250, 80, 100],\n",
    "               258: [180, 30, 80],\n",
    "               259: [255, 0, 0]},\n",
    " 'content': {0: 0.018889854628292943,\n",
    "             1: 0.0002937197336781505,\n",
    "             10: 0.040818519255974316,\n",
    "             11: 0.00016609538710764618,\n",
    "             13: 2.7879693665067774e-05,\n",
    "             15: 0.00039838616015114444,\n",
    "             16: 0.0,\n",
    "             18: 0.0020633612104619787,\n",
    "             20: 0.0016218197275284021,\n",
    "             30: 0.00017698551338515307,\n",
    "             31: 1.1065903904919655e-08,\n",
    "             32: 5.532951952459828e-09,\n",
    "             40: 0.1987493871255525,\n",
    "             44: 0.014717169549888214,\n",
    "             48: 0.14392298360372,\n",
    "             49: 0.0039048553037472045,\n",
    "             50: 0.1326861944777486,\n",
    "             51: 0.0723592229456223,\n",
    "             52: 0.002395131480328884,\n",
    "             60: 4.7084144280367186e-05,\n",
    "             70: 0.26681502148037506,\n",
    "             71: 0.006035012012626033,\n",
    "             72: 0.07814222006271769,\n",
    "             80: 0.002855498193863172,\n",
    "             81: 0.0006155958086189918,\n",
    "             99: 0.009923127583046915,\n",
    "             252: 0.001789309418528068,\n",
    "             253: 0.00012709999297008662,\n",
    "             254: 0.00016059776092534436,\n",
    "             255: 3.745553104802113e-05,\n",
    "             256: 0.0,\n",
    "             257: 0.00011351574470342043,\n",
    "             258: 0.00010157861367183268,\n",
    "             259: 4.3840131989471124e-05},\n",
    " 'labels': {0: 'unlabeled',\n",
    "            1: 'outlier',\n",
    "            10: 'car',\n",
    "            11: 'bicycle',\n",
    "            13: 'bus',\n",
    "            15: 'motorcycle',\n",
    "            16: 'on-rails',\n",
    "            18: 'truck',\n",
    "            20: 'other-vehicle',\n",
    "            30: 'person',\n",
    "            31: 'bicyclist',\n",
    "            32: 'motorcyclist',\n",
    "            40: 'road',\n",
    "            44: 'parking',\n",
    "            48: 'sidewalk',\n",
    "            49: 'other-ground',\n",
    "            50: 'building',\n",
    "            51: 'fence',\n",
    "            52: 'other-structure',\n",
    "            60: 'lane-marking',\n",
    "            70: 'vegetation',\n",
    "            71: 'trunk',\n",
    "            72: 'terrain',\n",
    "            80: 'pole',\n",
    "            81: 'traffic-sign',\n",
    "            99: 'other-object',\n",
    "            252: 'moving-car',\n",
    "            253: 'moving-bicyclist',\n",
    "            254: 'moving-person',\n",
    "            255: 'moving-motorcyclist',\n",
    "            256: 'moving-on-rails',\n",
    "            257: 'moving-bus',\n",
    "            258: 'moving-truck',\n",
    "            259: 'moving-other-vehicle'},\n",
    " 'learning_ignore': {0: True,\n",
    "                     1: False,\n",
    "                     2: False,\n",
    "                     3: False,\n",
    "                     4: False,\n",
    "                     5: False,\n",
    "                     6: False,\n",
    "                     7: False,\n",
    "                     8: False,\n",
    "                     9: False,\n",
    "                     10: False,\n",
    "                     11: False,\n",
    "                     12: False,\n",
    "                     13: False,\n",
    "                     14: False,\n",
    "                     15: False,\n",
    "                     16: False,\n",
    "                     17: False,\n",
    "                     18: False,\n",
    "                     19: False},\n",
    " 'learning_map': {0: 0,\n",
    "                  1: 0,\n",
    "                  10: 1,\n",
    "                  11: 2,\n",
    "                  13: 5,\n",
    "                  15: 3,\n",
    "                  16: 5,\n",
    "                  18: 4,\n",
    "                  20: 5,\n",
    "                  30: 6,\n",
    "                  31: 7,\n",
    "                  32: 8,\n",
    "                  40: 9,\n",
    "                  44: 10,\n",
    "                  48: 11,\n",
    "                  49: 12,\n",
    "                  50: 13,\n",
    "                  51: 14,\n",
    "                  52: 0,\n",
    "                  60: 9,\n",
    "                  70: 15,\n",
    "                  71: 16,\n",
    "                  72: 17,\n",
    "                  80: 18,\n",
    "                  81: 19,\n",
    "                  99: 0,\n",
    "                  252: 1,\n",
    "                  253: 7,\n",
    "                  254: 6,\n",
    "                  255: 8,\n",
    "                  256: 5,\n",
    "                  257: 5,\n",
    "                  258: 4,\n",
    "                  259: 5},\n",
    " 'learning_map_inv': {0: 0,\n",
    "                      1: 10,\n",
    "                      2: 11,\n",
    "                      3: 15,\n",
    "                      4: 18,\n",
    "                      5: 20,\n",
    "                      6: 30,\n",
    "                      7: 31,\n",
    "                      8: 32,\n",
    "                      9: 40,\n",
    "                      10: 44,\n",
    "                      11: 48,\n",
    "                      12: 49,\n",
    "                      13: 50,\n",
    "                      14: 51,\n",
    "                      15: 70,\n",
    "                      16: 71,\n",
    "                      17: 72,\n",
    "                      18: 80,\n",
    "                      19: 81},\n",
    " 'name': 'kitti',\n",
    " 'split': {'test': [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21],\n",
    "           'train': [0, 1, 2, 3, 4, 5, 6, 7, 9, 10],\n",
    "           'valid': [8]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## arch cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_cfg = {\n",
    " 'dataset': {\n",
    "     'labels': 'kitti',\n",
    "     'max_points': 150000,\n",
    "     'scans': 'kitti',\n",
    "\n",
    "     # KITTI\n",
    "     'sensor': {\n",
    "         'fov_down': -25,\n",
    "         'fov_up': 3,\n",
    "\n",
    "         'img_means': [12.12, 10.88, 0.23, -1.04, 0.21], # range, x, y, z, signal\n",
    "         'img_stds': [12.32, 11.47, 6.91, 0.86, 0.16], # range, x, y, z, signal\n",
    "\n",
    "         'img_prop': {\n",
    "             'height': 64,\n",
    "             'width': 2048,\n",
    "         },\n",
    "         'name': 'HDL64',\n",
    "         'type': 'spherical'\n",
    "     },\n",
    "\n",
    "     # HUSKY\n",
    "#      'sensor': {\n",
    "#          'fov_down': -30.67,\n",
    "#          'fov_up': 10.67,\n",
    "\n",
    "#          'img_means': [8.75550024, 0.07549276, -1.13823771, -0.13648431, 0.06386641], # range, x, y, z, signal\n",
    "#          'img_stds': [10.08941738, 10.40510729, 8.21806914, 1.15425178, 0.07281147], # range, x, y, z, signal\n",
    "\n",
    "#          'img_prop': {\n",
    "#              'height': 32,\n",
    "#              'width': 2048,\n",
    "#              # TODO: scale?\n",
    "#              # 'width': 2169,\n",
    "#          },\n",
    "#          'name': 'HDL32',\n",
    "#          'type': 'spherical'\n",
    "#      },\n",
    " },\n",
    "\n",
    " 'post': {'CRF': {'params': False, 'train': True, 'use': False},\n",
    "          'KNN': {'params': {'cutoff': 1.0,\n",
    "                             'knn': 5,\n",
    "                             'search': 5,\n",
    "                             'sigma': 1.0},\n",
    "                  'use': True}},\n",
    "\n",
    " 'train': {'batch_size': 30,\n",
    "           'epsilon_w': 0.001,\n",
    "           'loss': 'xentropy',\n",
    "           'lr': 0.05,\n",
    "           'lr_decay': 0.99,\n",
    "           'max_epochs': 40,\n",
    "           'momentum': 0.9,\n",
    "           'report_batch': 10,\n",
    "           'report_epoch': 1,\n",
    "           'save_scans': True,\n",
    "           'save_summary': False,\n",
    "           'show_scans': False,\n",
    "           'w_decay': 0.0001,\n",
    "           'workers': 4,\n",
    "           'wup_epochs': 1}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dir_path = '/home/crowbar/2-projects/SalsaNext/logs/40epoch-wo-rem'\n",
    "# model_dir_path = '/home/crowbar/2-projects/SalsaNext/logs/40epoch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir_path = '/datasets/KITTI_Odometry/dataset/sequences/12/velodyne/'\n",
    "# dataset_dir_path = '/datasets/Husky-NKBVS/14/velodyne_points/clouds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dir_path = '/home/crowbar/2-projects/SalsaNext/predicted/kitti/'\n",
    "log_dir_path = '/home/crowbar/2-projects/SalsaNext/predicted/w-rem/kitti-sem-12/'\n",
    "# log_dir_path = '/home/crowbar/2-projects/SalsaNext/predicted/w-rem/husky/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'salsanext'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENSOR:\n",
      "{'fov_down': -25,\n",
      " 'fov_up': 3,\n",
      " 'img_means': [12.12, 10.88, 0.23, -1.04, 0.21],\n",
      " 'img_prop': {'height': 64, 'width': 2048},\n",
      " 'img_stds': [12.32, 11.47, 6.91, 0.86, 0.16],\n",
      " 'name': 'HDL64',\n",
      " 'type': 'spherical'}\n",
      "Dataset folder exists! Using clouds from /datasets/KITTI_Odometry/dataset/sequences/12/velodyne/\n",
      "Parsing dataset... \n",
      "Using 1061 scans\n",
      "modeldir: /home/crowbar/2-projects/SalsaNext/logs/40epoch\n",
      "model_path: /home/crowbar/2-projects/SalsaNext/logs/40epoch/SalsaNet\n",
      "********************************************************************************\n",
      "Cleaning point-clouds with kNN post-processing\n",
      "kNN parameters:\n",
      "knn: 5\n",
      "search: 5\n",
      "sigma: 1.0\n",
      "cutoff: 1.0\n",
      "nclasses: 20\n",
      "********************************************************************************\n",
      "Infering in device:  cuda\n"
     ]
    }
   ],
   "source": [
    "user = User(arch_cfg, data_cfg, dataset_dir_path, log_dir_path, model_dir_path, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan: 000000.label\n",
      "Infer time: 2.1194975689868443 sec\n",
      "Scan: 000001.label\n",
      "Infer time: 0.01803598797414452 sec\n",
      "Scan: 000002.label\n",
      "Infer time: 0.01265618996694684 sec\n",
      "Scan: 000003.label\n",
      "Infer time: 0.012610113015398383 sec\n",
      "Scan: 000004.label\n",
      "Infer time: 0.012641739042010158 sec\n",
      "Scan: 000005.label\n",
      "Infer time: 0.028232073003891855 sec\n",
      "Scan: 000006.label\n",
      "Infer time: 0.020533878006972373 sec\n",
      "Scan: 000007.label\n",
      "Infer time: 0.01653581199934706 sec\n",
      "Scan: 000008.label\n",
      "Infer time: 0.022206934983842075 sec\n",
      "Scan: 000009.label\n",
      "Infer time: 0.03361245500855148 sec\n",
      "Scan: 000010.label\n",
      "Infer time: 0.012850310013163835 sec\n",
      "Scan: 000011.label\n",
      "Infer time: 0.01280138100264594 sec\n",
      "Scan: 000012.label\n",
      "Infer time: 0.01252277399180457 sec\n",
      "Scan: 000013.label\n",
      "Infer time: 0.15979771997081116 sec\n",
      "Scan: 000014.label\n",
      "Infer time: 0.012641876994166523 sec\n",
      "Scan: 000015.label\n",
      "Infer time: 0.012730424001347274 sec\n",
      "Scan: 000016.label\n",
      "Infer time: 0.012720702972728759 sec\n",
      "Scan: 000017.label\n",
      "Infer time: 0.01275649998569861 sec\n",
      "Scan: 000018.label\n",
      "Infer time: 0.012865678989328444 sec\n",
      "Scan: 000019.label\n",
      "Infer time: 0.012897406006231904 sec\n",
      "Scan: 000020.label\n",
      "Infer time: 0.012505321006756276 sec\n",
      "Scan: 000021.label\n",
      "Infer time: 0.01330952299758792 sec\n",
      "Scan: 000022.label\n",
      "Infer time: 0.012699774000793695 sec\n",
      "Scan: 000023.label\n",
      "Infer time: 0.012628256052266806 sec\n",
      "Scan: 000024.label\n",
      "Infer time: 0.012631396995857358 sec\n",
      "Scan: 000025.label\n",
      "Infer time: 0.012681371998041868 sec\n",
      "Scan: 000026.label\n",
      "Infer time: 0.012594914995133877 sec\n",
      "Scan: 000027.label\n",
      "Infer time: 0.012642596964724362 sec\n",
      "Scan: 000028.label\n",
      "Infer time: 0.012544535973574966 sec\n",
      "Scan: 000029.label\n",
      "Infer time: 0.012583692034240812 sec\n",
      "Scan: 000030.label\n",
      "Infer time: 0.01249500596895814 sec\n",
      "Scan: 000031.label\n",
      "Infer time: 0.012589616002514958 sec\n",
      "Scan: 000032.label\n",
      "Infer time: 0.01256242097588256 sec\n",
      "Scan: 000033.label\n",
      "Infer time: 0.013666231010574847 sec\n",
      "Scan: 000034.label\n",
      "Infer time: 0.012558033980894834 sec\n",
      "Scan: 000035.label\n",
      "Infer time: 0.012714152981061488 sec\n",
      "Scan: 000036.label\n",
      "Infer time: 0.012506164028309286 sec\n",
      "Scan: 000037.label\n",
      "Infer time: 0.012570580991450697 sec\n",
      "Scan: 000038.label\n",
      "Infer time: 0.012559410999529064 sec\n",
      "Scan: 000039.label\n",
      "Infer time: 0.018879270006436855 sec\n",
      "Scan: 000040.label\n",
      "Infer time: 0.019601573003455997 sec\n",
      "Scan: 000041.label\n",
      "Infer time: 0.01609586999984458 sec\n",
      "Scan: 000042.label\n",
      "Infer time: 0.018555677961558104 sec\n",
      "Scan: 000043.label\n",
      "Infer time: 0.018700192973483354 sec\n",
      "Scan: 000044.label\n",
      "Infer time: 0.022128809010609984 sec\n",
      "Scan: 000045.label\n",
      "Infer time: 0.012478299962822348 sec\n",
      "Scan: 000046.label\n",
      "Infer time: 0.012536099995486438 sec\n",
      "Scan: 000047.label\n",
      "Infer time: 0.012941853958182037 sec\n",
      "Scan: 000048.label\n",
      "Infer time: 0.012844096985645592 sec\n",
      "Scan: 000049.label\n",
      "Infer time: 0.012521881028078496 sec\n",
      "Scan: 000050.label\n",
      "Infer time: 0.012997597979847342 sec\n",
      "Scan: 000051.label\n",
      "Infer time: 0.012882573995739222 sec\n",
      "Scan: 000052.label\n",
      "Infer time: 0.012973630975466222 sec\n",
      "Scan: 000053.label\n",
      "Infer time: 0.012942995002958924 sec\n",
      "Scan: 000054.label\n",
      "Infer time: 0.01298899098765105 sec\n",
      "Scan: 000055.label\n",
      "Infer time: 0.012692709045950323 sec\n",
      "Scan: 000056.label\n",
      "Infer time: 0.029507964034564793 sec\n",
      "Scan: 000057.label\n",
      "Infer time: 0.024119345005601645 sec\n",
      "Scan: 000058.label\n",
      "Infer time: 0.026428523007780313 sec\n",
      "Scan: 000059.label\n",
      "Infer time: 0.024083923955913633 sec\n",
      "Scan: 000060.label\n",
      "Infer time: 0.012595499982126057 sec\n",
      "Scan: 000061.label\n",
      "Infer time: 0.012571006955113262 sec\n",
      "Scan: 000062.label\n",
      "Infer time: 0.012676482030656189 sec\n",
      "Scan: 000063.label\n",
      "Infer time: 0.013088104024063796 sec\n",
      "Scan: 000064.label\n",
      "Infer time: 0.012686814006883651 sec\n",
      "Scan: 000065.label\n",
      "Infer time: 0.012868945952504873 sec\n",
      "Scan: 000066.label\n",
      "Infer time: 0.012906896998174489 sec\n",
      "Scan: 000067.label\n",
      "Infer time: 0.012965336965862662 sec\n",
      "Scan: 000068.label\n",
      "Infer time: 0.020631787017919123 sec\n",
      "Scan: 000069.label\n",
      "Infer time: 0.012941518041770905 sec\n",
      "Scan: 000070.label\n",
      "Infer time: 0.013049016008153558 sec\n",
      "Scan: 000071.label\n",
      "Infer time: 0.012598516012076288 sec\n",
      "Scan: 000072.label\n",
      "Infer time: 0.012569212005473673 sec\n",
      "Scan: 000073.label\n",
      "Infer time: 0.01257251703646034 sec\n",
      "Scan: 000074.label\n",
      "Infer time: 0.01472039200598374 sec\n",
      "Scan: 000075.label\n",
      "Infer time: 0.013587346009444445 sec\n",
      "Scan: 000076.label\n",
      "Infer time: 0.01336325501324609 sec\n",
      "Scan: 000077.label\n",
      "Infer time: 0.034097724012099206 sec\n",
      "Scan: 000078.label\n",
      "Infer time: 0.03437673597363755 sec\n",
      "Scan: 000079.label\n",
      "Infer time: 0.03281203500228003 sec\n",
      "Scan: 000080.label\n",
      "Infer time: 0.033808744978159666 sec\n",
      "Scan: 000081.label\n",
      "Infer time: 0.012620908964890987 sec\n",
      "Scan: 000082.label\n",
      "Infer time: 0.014180880039930344 sec\n",
      "Scan: 000083.label\n",
      "Infer time: 0.012649425014387816 sec\n",
      "Scan: 000084.label\n",
      "Infer time: 0.012736248027067631 sec\n",
      "Scan: 000085.label\n",
      "Infer time: 0.019647973007522523 sec\n",
      "Scan: 000086.label\n",
      "Infer time: 0.022992466983851045 sec\n",
      "Scan: 000087.label\n",
      "Infer time: 0.018824587983544916 sec\n",
      "Scan: 000088.label\n",
      "Infer time: 0.018788185028824955 sec\n",
      "Scan: 000089.label\n",
      "Infer time: 0.018447923008352518 sec\n",
      "Scan: 000090.label\n",
      "Infer time: 0.018616302986629307 sec\n",
      "Scan: 000091.label\n",
      "Infer time: 0.019371757982298732 sec\n",
      "Scan: 000092.label\n",
      "Infer time: 0.01263219496468082 sec\n",
      "Scan: 000093.label\n",
      "Infer time: 0.01467822800623253 sec\n",
      "Scan: 000094.label\n",
      "Infer time: 0.012727324035950005 sec\n",
      "Scan: 000095.label\n",
      "Infer time: 0.012765192019287497 sec\n",
      "Scan: 000096.label\n",
      "Infer time: 0.012645637965761125 sec\n",
      "Scan: 000097.label\n",
      "Infer time: 0.012657797022257 sec\n",
      "Scan: 000098.label\n",
      "Infer time: 0.012683562992606312 sec\n",
      "Scan: 000099.label\n",
      "Infer time: 0.01262922998284921 sec\n",
      "Scan: 000100.label\n",
      "Infer time: 0.013511576049495488 sec\n",
      "Scan: 000101.label\n",
      "Infer time: 0.01255374203901738 sec\n",
      "Scan: 000102.label\n",
      "Infer time: 0.012546398967970163 sec\n",
      "Scan: 000103.label\n",
      "Infer time: 0.01250161399366334 sec\n",
      "Scan: 000104.label\n",
      "Infer time: 0.012553494016174227 sec\n",
      "Scan: 000105.label\n",
      "Infer time: 0.012516926974058151 sec\n",
      "Scan: 000106.label\n",
      "Infer time: 0.012563460972160101 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e2d038d67762>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-e472d13d319f>\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         self.infer_subset(loader=self.parser.get_test_set(),\n\u001b[0;32m---> 90\u001b[0;31m                           to_orig_fn=self.parser.to_original)\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished Infering'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-e472d13d319f>\u001b[0m in \u001b[0;36minfer_subset\u001b[0;34m(self, loader, to_orig_fn)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;31m# USING ONLY SUBSET FOR RESEARCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mproj_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproj_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproj_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munproj_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpoints\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                 \u001b[0mlimit\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/salsanext/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/salsanext/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-e60d24f05e02>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# make a tensor of the uncompressed data (with the max num points)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0munproj_n_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0munproj_xyz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0munproj_xyz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0munproj_n_points\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0munproj_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_points\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "user.infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
